#!/usr/bin/env python3
"""
Analizador de Art√≠culos de Mar√≠n - HorizontAI
==============================================

Script completo para an√°lisis de sentimientos, temas e intensidad emocional
de art√≠culos de noticias locales de Mar√≠n.

Funcionalidades:
- Detecci√≥n autom√°tica de idioma (Espa√±ol/Gallego)
- An√°lisis de sentimientos con BETO/Bertinho
- Clasificaci√≥n de temas generales (Phase 1)
- An√°lisis pol√≠tico avanzado (Phase 2 - solo art√≠culos pol√≠ticos)
- An√°lisis de intensidad emocional

Autor: HorizontAI Team
Fecha: Junio 2025
"""

import os
# CONFIGURAR CACHE EN DISCO D: ANTES DE IMPORTAR TRANSFORMERS
os.environ['TRANSFORMERS_CACHE'] = 'D:/huggingface_cache'
os.environ['HF_HOME'] = 'D:/huggingface_cache'
os.environ['HF_DATASETS_CACHE'] = 'D:/huggingface_cache'

import pandas as pd
import numpy as np
import re
import warnings
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from fast_langdetect import detect
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

warnings.filterwarnings('ignore')

# Crear directorio cache si no existe
cache_dir = 'D:/huggingface_cache'
if not os.path.exists(cache_dir):
    os.makedirs(cache_dir)
    print(f"üìÅ Directorio cache creado en: {cache_dir}")

@dataclass
class AnalysisResult:
    """Estructura para almacenar resultados del an√°lisis"""
    idioma: str
    confianza_idioma: float
    tema_principal: str
    subtema: Optional[str]
    sentimiento: str
    score_sentimiento: float
    intensidad_emocional: int
    es_politico: bool
    politicos_mencionados: List[str]
    partidos_mencionados: List[str]
    palabras_clave: List[str]

class DetectorIdioma:
    """Detector de idioma usando FastText"""
    
    def __init__(self):
        self.idiomas_soportados = ['es', 'gl', 'ca', 'eu', 'pt']
    
    def detectar(self, texto: str) -> Tuple[str, float]:
        """
        Detecta el idioma del texto
        
        Args:
            texto: Texto a analizar
            
        Returns:
            Tuple con (idioma, confianza)
        """
        try:
            if not texto or len(texto.strip()) < 10:
                return 'es', 0.5  # Default espa√±ol para textos muy cortos
                
            resultado = detect(texto)
            idioma = resultado['lang']
            confianza = resultado['score']
            
            # Si no es espa√±ol o gallego, defaultear a espa√±ol
            if idioma not in ['es', 'gl']:
                return 'es', 0.6
                
            return idioma, confianza
            
        except Exception as e:
            print(f"Error en detecci√≥n de idioma: {e}")
            return 'es', 0.5

class AnalizadorSentimientos:
    """Analizador de sentimientos con BETO y Bertinho"""
    
    def __init__(self):
        self.modelo_espanol = None
        self.modelo_gallego = None
        self.tokenizer_espanol = None
        self.tokenizer_gallego = None
        self._cargar_modelos()
    
    def _cargar_modelos(self):
        """Carga los modelos BETO y Bertinho"""
        try:
            print("üîÑ Cargando BETO (Espa√±ol)...")
            self.tokenizer_espanol = AutoTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')
            self.modelo_espanol = AutoModelForSequenceClassification.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')
            
            print("üîÑ Cargando Bertinho (Gallego)...")
            self.tokenizer_gallego = AutoTokenizer.from_pretrained('dvilares/bertinho-gl-base-cased')
            self.modelo_gallego = AutoModelForSequenceClassification.from_pretrained('dvilares/bertinho-gl-base-cased')
            
            print("‚úÖ Modelos cargados correctamente")
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error cargando modelos: {e}")
            print("üìù Usando pipeline por defecto...")
            self._cargar_pipeline_alternativo()
    
    def _cargar_pipeline_alternativo(self):
        """Pipeline alternativo si fallan los modelos principales"""
        try:
            self.pipeline_es = pipeline("sentiment-analysis", 
                                      model="nlptown/bert-base-multilingual-uncased-sentiment",
                                      device=0 if torch.cuda.is_available() else -1)
            print("‚úÖ Pipeline alternativo cargado")
        except:
            print("‚ö†Ô∏è Usando an√°lisis b√°sico de sentimientos")
            self.pipeline_es = None
    
    def analizar(self, texto: str, idioma: str) -> Tuple[str, float]:
        """
        Analiza el sentimiento del texto
        
        Args:
            texto: Texto a analizar
            idioma: 'es' para espa√±ol, 'gl' para gallego
            
        Returns:
            Tuple con (sentimiento, score)
        """
        try:
            if not texto or len(texto.strip()) < 5:
                return 'neutral', 0.5
            
            # An√°lisis b√°sico por palabras clave si no hay modelos
            if not self.modelo_espanol and not self.pipeline_es:
                return self._analisis_basico(texto)
            
            # Usar pipeline si est√° disponible
            if self.pipeline_es:
                resultado = self.pipeline_es(texto)[0]
                label = resultado['label'].lower()
                score = resultado['score']
                
                # Mapear labels del modelo
                if 'pos' in label or '4' in label or '5' in label:
                    return 'positivo', score
                elif 'neg' in label or '1' in label or '2' in label:
                    return 'negativo', score
                else:
                    return 'neutral', score
            
            return self._analisis_basico(texto)
            
        except Exception as e:
            print(f"Error en an√°lisis de sentimientos: {e}")
            return self._analisis_basico(texto)
    
    def _analisis_basico(self, texto: str) -> Tuple[str, float]:
        """An√°lisis b√°sico basado en palabras clave"""
        texto_lower = texto.lower()
        
        palabras_positivas = [
            '√©xito', 'excelente', 'bueno', 'magn√≠fico', 'perfecto', 'logro', 
            'victoria', 'alegr√≠a', 'felicidad', 'prosperidad', 'avance',
            'bo', 'excelente', 'fant√°stico', 'alegre', 'contento'  # gallego
        ]
        
        palabras_negativas = [
            'problema', 'crisis', 'malo', 'terrible', 'fracaso', 'error',
            'conflicto', 'pol√©mica', 'esc√°ndalo', 'cr√≠tica', 'denuncia',
            'mal', 'problema', 'crise', 'terrible', 'conflito'  # gallego
        ]
        
        score_pos = sum(1 for palabra in palabras_positivas if palabra in texto_lower)
        score_neg = sum(1 for palabra in palabras_negativas if palabra in texto_lower)
        
        if score_pos > score_neg:
            return 'positivo', min(0.6 + (score_pos * 0.1), 0.95)
        elif score_neg > score_pos:
            return 'negativo', min(0.6 + (score_neg * 0.1), 0.95)
        else:
            return 'neutral', 0.5

class ClasificadorTemas:
    """Clasificador de temas generales de art√≠culos"""
    
    def __init__(self):
        self.temas_keywords = {
            'necrol√≥gica': [
                'fallece', 'muerte', 'funeral', 'entierro', 'defunci√≥n', '√≥bito',
                'faleceu', 'morte', 'funeral', 'enterro'  # gallego
            ],
            'pol√≠tica': [
                'alcalde', 'concejo', 'elecciones', 'partido', 'pol√≠tico', 'gobierno',
                'pp', 'psoe', 'bng', 'pazos', 'ramallo', 'santos',
                'alcalde', 'concello', 'elecci√≥ns', 'partido', 'pol√≠tico', 'goberno'  # gallego
            ],
            'empresarial': [
                'empresa', 'negocio', 'comercio', 'industria', 'empleo', 'trabajo',
                'econ√≥mico', 'inversi√≥n', 'facturaci√≥n', 'beneficios',
                'empresa', 'negocio', 'comercio', 'industria', 'emprego', 'traballo'  # gallego
            ],
            'opini√≥n': [
                'opini√≥n', 'editorial', 'carta', 'director', 'columna', 'art√≠culo',
                'opina', 'considera', 'cree', 'piensa',
                'opini√≥n', 'editorial', 'carta', 'director', 'columna', 'artigo'  # gallego
            ],
            'cultura': [
                'festival', 'concierto', 'teatro', 'm√∫sica', 'arte', 'cultura',
                'exposici√≥n', 'evento', 'celebraci√≥n', 'tradici√≥n',
                'festival', 'concerto', 'teatro', 'm√∫sica', 'arte', 'cultura'  # gallego
            ],
            'obras': [
                'obras', 'construcci√≥n', 'infraestructura', 'urbanismo', 'proyecto',
                'reforma', 'mejora', 'renovaci√≥n', 'acondicionamiento',
                'obras', 'construci√≥n', 'infraestrutura', 'urbanismo', 'proxecto'  # gallego
            ],
            'trabajo': [
                'sindicato', 'convenio', 'empleo', 'trabajadores', 'laboral',
                'huelga', 'despido', 'contrato', 'salario',
                'sindicato', 'convenio', 'emprego', 'traballadores', 'laboral'  # gallego
            ],
            'deportes': [
                'f√∫tbol', 'deporte', 'equipo', 'partido', 'liga', 'competici√≥n',
                'entrenador', 'jugador', 'victoria', 'derrota',
                'f√∫tbol', 'deporte', 'equipo', 'partido', 'liga', 'competici√≥n'  # gallego
            ]
        }
    
    def clasificar(self, titulo: str, resumen: str = "") -> Tuple[str, List[str]]:
        """
        Clasifica el tema principal del art√≠culo
        
        Args:
            titulo: T√≠tulo del art√≠culo
            resumen: Resumen del art√≠culo (opcional)
            
        Returns:
            Tuple con (tema_principal, palabras_clave_encontradas)
        """
        texto_completo = f"{titulo} {resumen}".lower()
        
        scores_temas = {}
        palabras_encontradas = []
        
        for tema, keywords in self.temas_keywords.items():
            score = 0
            for keyword in keywords:
                if keyword in texto_completo:
                    score += 1
                    palabras_encontradas.append(keyword)
            
            # Peso extra para keywords en el t√≠tulo
            titulo_lower = titulo.lower()
            for keyword in keywords:
                if keyword in titulo_lower:
                    score += 0.5
            
            scores_temas[tema] = score
        
        # Tema con mayor score
        if scores_temas and max(scores_temas.values()) > 0:
            tema_principal = max(scores_temas, key=scores_temas.get)
        else:
            tema_principal = 'general'
        
        return tema_principal, palabras_encontradas

class AnalizadorPolitico:
    """An√°lisis pol√≠tico avanzado (Phase 2) para art√≠culos pol√≠ticos"""
    
    def __init__(self):
        self.politicos_locales = {
            'manuel pazos': ['manuel pazos', 'pazos'],
            'mar√≠a ramallo': ['mar√≠a ramallo', 'ramallo', 'maria ramallo'],
            'luc√≠a santos': ['luc√≠a santos', 'santos', 'lucia santos']
        }
        
        self.partidos = {
            'pp': ['pp', 'partido popular'],
            'psoe': ['psoe', 'partido socialista', 'psdeg'],
            'bng': ['bng', 'bloque nacionalista galego', 'bloque']
        }
        
        self.palabras_intensidad = {
            'muy_alta': [
                'esc√°ndalo', 'corrupci√≥n', 'fraude', 'dimisi√≥n', 'crisis',
                'pol√©mica', 'conflicto', 'enfrentamiento', 'ruptura',
                'esc√°ndalo', 'corrupci√≥n', 'fraude', 'dimisi√≥n', 'crise'  # gallego
            ],
            'alta': [
                'cr√≠tica', 'denuncia', 'protesta', 'oposici√≥n', 'rechazo',
                'debate', 'tensi√≥n', 'discrepancia', 'controversia',
                'cr√≠tica', 'denuncia', 'protesta', 'oposici√≥n', 'rexeitamento'  # gallego
            ],
            'media': [
                'propuesta', 'proyecto', 'iniciativa', 'medida', 'plan',
                'anuncio', 'declaraci√≥n', 'reuni√≥n', 'acuerdo',
                'proposta', 'proxecto', 'iniciativa', 'medida', 'plan'  # gallego
            ]
        }
    
    def es_articulo_politico(self, titulo: str, resumen: str = "") -> bool:
        """Determina si un art√≠culo es pol√≠tico"""
        texto_completo = f"{titulo} {resumen}".lower()
        
        # Buscar pol√≠ticos locales
        for politico, variantes in self.politicos_locales.items():
            if any(variante in texto_completo for variante in variantes):
                return True
        
        # Buscar partidos
        for partido, variantes in self.partidos.items():
            if any(variante in texto_completo for variante in variantes):
                return True
        
        # Palabras pol√≠ticas generales
        palabras_politicas = [
            'alcalde', 'concejal', 'gobierno', 'municipal', 'ayuntamiento',
            'pleno', 'elecciones', 'votos', 'campa√±a', 'pol√≠tico',
            'alcalde', 'concelleiro', 'goberno', 'municipal', 'concello'  # gallego
        ]
        
        return any(palabra in texto_completo for palabra in palabras_politicas)
    
    def analizar_intensidad(self, titulo: str, resumen: str = "") -> int:
        """
        Analiza la intensidad emocional/pol√≠tica del art√≠culo
        
        Returns:
            Escala 1-5 (1=neutral, 5=muy pasional)
        """
        texto_completo = f"{titulo} {resumen}".lower()
        
        score_intensidad = 1
        
        # Contar palabras de alta intensidad
        muy_alta = sum(1 for palabra in self.palabras_intensidad['muy_alta'] 
                      if palabra in texto_completo)
        alta = sum(1 for palabra in self.palabras_intensidad['alta'] 
                  if palabra in texto_completo)
        media = sum(1 for palabra in self.palabras_intensidad['media'] 
                   if palabra in texto_completo)
        
        # Calcular score
        score_intensidad += muy_alta * 1.5
        score_intensidad += alta * 1.0
        score_intensidad += media * 0.5
        
        # Peso extra si est√° en el t√≠tulo
        titulo_lower = titulo.lower()
        if any(palabra in titulo_lower for palabra in self.palabras_intensidad['muy_alta']):
            score_intensidad += 1
        
        # Normalizar a escala 1-5
        return min(int(score_intensidad), 5)
    
    def extraer_entidades_politicas(self, titulo: str, resumen: str = "") -> Tuple[List[str], List[str]]:
        """Extrae pol√≠ticos y partidos mencionados"""
        texto_completo = f"{titulo} {resumen}".lower()
        
        politicos_encontrados = []
        partidos_encontrados = []
        
        # Buscar pol√≠ticos
        for politico, variantes in self.politicos_locales.items():
            if any(variante in texto_completo for variante in variantes):
                politicos_encontrados.append(politico)
        
        # Buscar partidos
        for partido, variantes in self.partidos.items():
            if any(variante in texto_completo for variante in variantes):
                partidos_encontrados.append(partido)
        
        return politicos_encontrados, partidos_encontrados

class AnalizadorArticulosMarin:
    """Clase principal que coordina todos los an√°lisis"""
    
    def __init__(self):
        print("üöÄ Inicializando Analizador de Art√≠culos de Mar√≠n...")
        self.detector_idioma = DetectorIdioma()
        self.analizador_sentimientos = AnalizadorSentimientos()
        self.clasificador_temas = ClasificadorTemas()
        self.analizador_politico = AnalizadorPolitico()
        print("‚úÖ Analizador inicializado correctamente")
    
    def analizar_articulo(self, titulo: str, resumen: str = "") -> AnalysisResult:
        """
        An√°lisis completo de un art√≠culo
        
        Args:
            titulo: T√≠tulo del art√≠culo
            resumen: Resumen del art√≠culo (opcional)
            
        Returns:
            AnalysisResult con todos los an√°lisis
        """
        if not titulo:
            raise ValueError("El t√≠tulo es obligatorio")
        
        texto_completo = f"{titulo} {resumen}" if resumen else titulo
        
        # Phase 1: An√°lisis b√°sico para todos los art√≠culos
        idioma, confianza_idioma = self.detector_idioma.detectar(texto_completo)
        sentimiento, score_sentimiento = self.analizador_sentimientos.analizar(texto_completo, idioma)
        tema_principal, palabras_clave = self.clasificador_temas.clasificar(titulo, resumen)
        
        # Determinar si es art√≠culo pol√≠tico
        es_politico = self.analizador_politico.es_articulo_politico(titulo, resumen)
        
        # Phase 2: An√°lisis avanzado solo para art√≠culos pol√≠ticos
        if es_politico:
            intensidad_emocional = self.analizador_politico.analizar_intensidad(titulo, resumen)
            politicos_mencionados, partidos_mencionados = self.analizador_politico.extraer_entidades_politicas(titulo, resumen)
            subtema = 'pol√≠tico_' + ('local' if politicos_mencionados else 'general')
        else:
            intensidad_emocional = 1  # Neutral para no pol√≠ticos
            politicos_mencionados = []
            partidos_mencionados = []
            subtema = None
        
        return AnalysisResult(
            idioma=idioma,
            confianza_idioma=confianza_idioma,
            tema_principal=tema_principal,
            subtema=subtema,
            sentimiento=sentimiento,
            score_sentimiento=score_sentimiento,
            intensidad_emocional=intensidad_emocional,
            es_politico=es_politico,
            politicos_mencionados=politicos_mencionados,
            partidos_mencionados=partidos_mencionados,
            palabras_clave=palabras_clave
        )
    
    def analizar_dataset(self, df: pd.DataFrame, columna_titulo: str, 
                        columna_resumen: str = None) -> pd.DataFrame:
        """
        Analiza un dataset completo de art√≠culos
        
        Args:
            df: DataFrame con los art√≠culos
            columna_titulo: Nombre de la columna con t√≠tulos
            columna_resumen: Nombre de la columna con res√∫menes (opcional)
            
        Returns:
            DataFrame con las nuevas columnas de an√°lisis
        """
        print(f"üìä Analizando {len(df)} art√≠culos...")
        
        resultados = []
        for idx, row in df.iterrows():
            if idx % 100 == 0:
                print(f"   Procesado: {idx}/{len(df)} art√≠culos")
            
            titulo = row[columna_titulo]
            resumen = row[columna_resumen] if columna_resumen else ""
            
            try:
                resultado = self.analizar_articulo(titulo, resumen)
                resultados.append(resultado)
            except Exception as e:
                print(f"Error procesando art√≠culo {idx}: {e}")
                # Resultado por defecto en caso de error
                resultado_default = AnalysisResult(
                    idioma='es', confianza_idioma=0.5, tema_principal='general',
                    subtema=None, sentimiento='neutral', score_sentimiento=0.5,
                    intensidad_emocional=1, es_politico=False,
                    politicos_mencionados=[], partidos_mencionados=[], palabras_clave=[]
                )
                resultados.append(resultado_default)
        
        # A√±adir columnas al DataFrame
        df_resultado = df.copy()
        df_resultado['idioma_detectado'] = [r.idioma for r in resultados]
        df_resultado['confianza_idioma'] = [r.confianza_idioma for r in resultados]
        df_resultado['tema_principal'] = [r.tema_principal for r in resultados]
        df_resultado['subtema'] = [r.subtema for r in resultados]
        df_resultado['sentimiento'] = [r.sentimiento for r in resultados]
        df_resultado['score_sentimiento'] = [r.score_sentimiento for r in resultados]
        df_resultado['intensidad_emocional'] = [r.intensidad_emocional for r in resultados]
        df_resultado['es_politico'] = [r.es_politico for r in resultados]
        df_resultado['politicos_mencionados'] = [r.politicos_mencionados for r in resultados]
        df_resultado['partidos_mencionados'] = [r.partidos_mencionados for r in resultados]
        df_resultado['palabras_clave'] = [r.palabras_clave for r in resultados]
        
        print("‚úÖ An√°lisis completado")
        return df_resultado
    
    def generar_reporte(self, df_analizado: pd.DataFrame) -> Dict:
        """Genera un reporte resumen del an√°lisis"""
        total_articulos = len(df_analizado)
        
        reporte = {
            'total_articulos': total_articulos,
            'idiomas': df_analizado['idioma_detectado'].value_counts().to_dict(),
            'temas': df_analizado['tema_principal'].value_counts().to_dict(),
            'sentimientos': df_analizado['sentimiento'].value_counts().to_dict(),
            'articulos_politicos': df_analizado['es_politico'].sum(),
            'intensidad_promedio': df_analizado['intensidad_emocional'].mean(),
            'politicos_mas_mencionados': self._contar_menciones(df_analizado, 'politicos_mencionados'),
            'partidos_mas_mencionados': self._contar_menciones(df_analizado, 'partidos_mencionados')
        }
        
        return reporte
    
    def _contar_menciones(self, df: pd.DataFrame, columna: str) -> Dict:
        """Cuenta menciones de entidades pol√≠ticas"""
        menciones = {}
        for lista_entidades in df[columna]:
            for entidad in lista_entidades:
                menciones[entidad] = menciones.get(entidad, 0) + 1
        return dict(sorted(menciones.items(), key=lambda x: x[1], reverse=True))

# Funci√≥n de utilidad para uso r√°pido
def analizar_articulos_marin(df: pd.DataFrame, col_titulo: str, col_resumen: str = None) -> pd.DataFrame:
    """
    Funci√≥n de conveniencia para an√°lisis r√°pido
    
    Args:
        df: DataFrame con art√≠culos
        col_titulo: Columna con t√≠tulos
        col_resumen: Columna con res√∫menes (opcional)
        
    Returns:
        DataFrame con an√°lisis completo
    """
    analizador = AnalizadorArticulosMarin()
    return analizador.analizar_dataset(df, col_titulo, col_resumen)

# Ejemplo de uso
if __name__ == "__main__":
    # Ejemplo de uso b√°sico
    print("üî¨ Ejemplo de an√°lisis individual:")
    
    analizador = AnalizadorArticulosMarin()
    
    # Test con art√≠culo pol√≠tico
    titulo_test = "Manuel Pazos critica duramente la gesti√≥n del PP en el ayuntamiento"
    resumen_test = "El alcalde socialista denunci√≥ irregularidades en el proyecto de obras"
    
    resultado = analizador.analizar_articulo(titulo_test, resumen_test)
    print(f"üì∞ T√≠tulo: {titulo_test}")
    print(f"üåç Idioma: {resultado.idioma} (confianza: {resultado.confianza_idioma:.2f})")
    print(f"üìÇ Tema: {resultado.tema_principal}")
    print(f"üòä Sentimiento: {resultado.sentimiento} (score: {resultado.score_sentimiento:.2f})")
    print(f"üî• Intensidad: {resultado.intensidad_emocional}/5")
    print(f"üèõÔ∏è Es pol√≠tico: {resultado.es_politico}")
    print(f"üë• Pol√≠ticos: {resultado.politicos_mencionados}")
    print(f"üéØ Partidos: {resultado.partidos_mencionados}")
    
    print("\n" + "="*60)
    print("‚úÖ Script listo para usar con tus datos!")
    print("üí° Usa: analizar_articulos_marin(tu_dataframe, 'title', 'summary')")